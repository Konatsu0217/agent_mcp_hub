import asyncio
import inspect
import json
import re
from typing import AsyncGenerator, Optional

import httpx
from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from tavily import TavilyClient

from mcp_server import MCPServer, Parameter


# ===================== é…ç½®ç®¡ç† =====================
class Settings:
    """ç®€å•çš„é…ç½®ç±»ï¼Œå¯ä»¥æ”¹æˆä»æ–‡ä»¶/æ•°æ®åº“åŠ è½½"""

    def __init__(self):
        self.tavily_api_key = "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"
        self.jina_api_key = ""  # å¯é€‰ï¼Œä¸å¡«å°±ä¸å¸¦ Authorization
        self.tavily_max_results = 5
        self.jina_max_length = 1500
        self.content_per_page = 1000


settings = Settings()

# ===================== åˆ›å»º MCP å®ä¾‹ =====================
mcp = MCPServer(name="Web Search MCP Server")


# ===================== è¾…åŠ©å‡½æ•° =====================

def clean_text(text: str, max_length: int = 2000) -> str:
    """æ¸…ç†å’Œæˆªæ–­æ–‡æœ¬"""
    if not text:
        return ""
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', text)
    if len(text) > max_length:
        text = text[:max_length] + "..."
    return text.strip()


def extract_main_content(html_text: str, max_length: int = 1500) -> str:
    """ä» Jina è¿”å›çš„æ–‡æœ¬ä¸­æå–ä¸»è¦å†…å®¹"""
    if not html_text:
        return ""

    lines = html_text.split('\n')
    content_lines = []
    skip_keywords = ['navigation', 'menu', 'footer', 'subscribe', 'cookie', 'privacy policy']

    for line in lines:
        line_lower = line.lower()
        if any(keyword in line_lower for keyword in skip_keywords):
            continue
        if line.strip():
            content_lines.append(line.strip())

    content = ' '.join(content_lines)
    return clean_text(content, max_length)


def format_sources(results: list) -> str:
    """æ ¼å¼åŒ–æ¥æºé“¾æ¥ï¼š[ç½‘ç«™åç§°](é“¾æ¥åœ°å€)"""
    sources = []
    for r in results:
        title = r.get("title", "æœªçŸ¥æ¥æº")
        url = r.get("url", "")
        if url:
            # ç§»é™¤æ‹¬å·å†…çš„ç©ºæ ¼
            sources.append(f"[{title}]({url.strip()})")
    return "\n".join(sources)


# ===================== æ ¸å¿ƒå·¥å…·å‡½æ•° =====================

async def jina_crawler_internal(
        original_url: str,
        max_length: Optional[int] = None
) -> str:
    """
    å†…éƒ¨ Jina çˆ¬è™«å‡½æ•°ï¼Œè¿”å›ç½‘é¡µå†…å®¹æ–‡æœ¬
    """
    if max_length is None:
        max_length = settings.jina_max_length

    detail_url = "https://r.jina.ai/"
    url = f"{detail_url}{original_url}"

    try:
        headers = {}
        if settings.jina_api_key:
            headers['Authorization'] = f'Bearer {settings.jina_api_key}'

        async with httpx.AsyncClient(timeout=20) as client:
            response = await client.get(url, headers=headers)

            if response.status_code == 200:
                content = extract_main_content(response.text, max_length)
                return content
            else:
                return f"è·å–{original_url}ç½‘é¡µä¿¡æ¯å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}"

    except Exception as e:
        return f"è·å–{original_url}ç½‘é¡µä¿¡æ¯å¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯ï¼š{str(e)}"


async def tavily_search_internal(
        query: str,
        max_results: Optional[int] = None
) -> dict:
    """
    å†…éƒ¨ Tavily æœç´¢å‡½æ•°ï¼Œè¿”å›ç»“æ„åŒ–æ•°æ®
    """
    if max_results is None:
        max_results = settings.tavily_max_results

    try:
        def sync_search():
            client = TavilyClient(api_key=settings.tavily_api_key)
            return client.search(
                query=query,
                max_results=max_results,
                include_answer=True,
                include_raw_content=False
            )

        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(None, sync_search)
        return response

    except Exception as e:
        print(f"Tavily search error: {e}")
        return {"results": [], "answer": ""}


# ===================== MCP å·¥å…·å®šä¹‰ =====================
'''
1. åˆ›å»ºMCPServerå®ä¾‹
2. ç”¨ @mcp.tool å£°æ˜å¯ä»¥è¢«å‘ç°çš„å·¥å…·
3. åˆ›å»ºFastAPIåº”ç”¨å®ä¾‹ï¼Œé…ç½®URLï¼Œè®°å¾—å¡«åˆ°å¤–é¢é‚£ä¸ª [mcp_servers_config.json] å½“ä¸­
4. è¿è¡Œä½ å†™å¥½çš„mcpServeræœåŠ¡ï¼Œ[/mcp]æ¥å£æ–¹æ³•å¯ä»¥ç›´æ¥copyï¼Œä¸ç”¨ç®¡
'''

@mcp.tool(name="echo", description="å›æ˜¾æ¶ˆæ¯")
def echo(message: str) -> str:
    return message

@mcp.tool(
    name="get_weather",
    description="æŸ¥è¯¢å¤©æ°”",
    parameters=[
        Parameter("city", "string", "è¦æŸ¥è¯¢å¤©æ°”çš„åŸå¸‚"),
        Parameter("date", "string", "è¦æŸ¥è¯¢çš„æ—¥æœŸ"),
    ]
)
def get_weather(city: str, date: str) -> str:
    if city == "åŒ—äº¬":
        return f"åŒ—äº¬åœ¨ {date} æ˜¯æ™´å¤©"
    elif city == "ä¸Šæµ·":
        return f"ä¸Šæµ·åœ¨ {date} æ˜¯å¤šäº‘"
    elif city == "å¹¿å·":
        return f"å¹¿å·åœ¨ {date} æ˜¯é˜´äº‘"
    else:
        return f"å¤©æ°”ä¿¡æ¯: {city} åœ¨ {date}"


@mcp.tool(
    name="tavily_search",
    description="é€šè¿‡Tavilyä¸“ä¸šæœç´¢APIè·å–é«˜è´¨é‡çš„ç½‘ç»œä¿¡æ¯ï¼Œç‰¹åˆ«é€‚åˆè·å–å®æ—¶æ•°æ®å’Œä¸“ä¸šåˆ†æã€‚è¿”å›ç»“æœåŒ…å«æœç´¢ç­”æ¡ˆå’Œæ¥æºé“¾æ¥ã€‚",
    parameters=[
        Parameter("query", "string", "éœ€è¦æœç´¢çš„å…³é”®è¯æˆ–è‡ªç„¶è¯­è¨€æŸ¥è¯¢è¯­å¥"),
        Parameter("max_results", "integer", "æœ€å¤§æœç´¢ç»“æœæ•°ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®å€¼", required=False),
    ]
)
async def tavily_search(
        query: str,
        max_results: Optional[int] = None
):
    """
    Tavily æœç´¢å·¥å…·ï¼šè¿”å›ç»“æ„åŒ–çš„æœç´¢ç»“æœ
    """
    search_result = await tavily_search_internal(query, max_results)
    results = search_result.get("results", [])
    answer = search_result.get("answer", "")

    res = clean_text(answer, 500)
    res += "\n ä¿¡æ¯æ¥æºï¼š"
    for r in results:
        res += f" [{r.get('snippet', '')}]({r.get('url', '')})"

    return res


@mcp.tool(
    name="jina_crawler",
    description="é€šè¿‡Jina AIçš„ç½‘é¡µçˆ¬å–APIè·å–æŒ‡å®šURLçš„ç½‘é¡µå†…å®¹ã€‚å¯ä»¥çˆ¬å–æœç´¢å¼•æ“è¿”å›çš„é“¾æ¥ï¼Œæˆ–ç”¨æˆ·æä¾›çš„ç½‘ç«™é“¾æ¥ã€‚æ³¨æ„ï¼šä¸è¦ä¼ å…¥æœ¬æœºåœ°å€(localhost/127.0.0.1)æˆ–å†…ç½‘åœ°å€ï¼ŒJinaæ— æ³•è®¿é—®è¿™äº›URLã€‚",
    parameters=[
        Parameter("original_url", "string", "éœ€è¦çˆ¬å–çš„åŸå§‹URLåœ°å€ï¼ˆå®Œæ•´çš„http/httpsé“¾æ¥ï¼‰"),
        Parameter("max_length", "integer", "è¿”å›å†…å®¹çš„æœ€å¤§å­—ç¬¦æ•°ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®å€¼", required=False),
    ]
)
async def jina_crawler(
        original_url: str,
        max_length: Optional[int] = None
):
    """
    Jina çˆ¬è™«å·¥å…·ï¼šæŠ“å–å•ä¸ªç½‘é¡µå†…å®¹
    """
    # æ£€æŸ¥æ˜¯å¦æ˜¯æœ¬åœ°/å†…ç½‘åœ°å€
    if any(pattern in original_url.lower() for pattern in ['localhost', '127.0.0.1', '192.168.', '10.', '172.16.']):
        return {
            "url": original_url,
            "success": False,
            "error": "ä¸æ”¯æŒçˆ¬å–æœ¬æœºæˆ–å†…ç½‘åœ°å€",
            "content": None
        }

    content = await jina_crawler_internal(original_url, max_length)

    # åˆ¤æ–­æ˜¯å¦æˆåŠŸ
    if content.startswith("è·å–") and "å¤±è´¥" in content:
        return {
            "url": original_url,
            "success": False,
            "error": content,
            "content": None
        }
    else:
        return {
            "url": original_url,
            "success": True,
            "content": content,
            "length": len(content)
        }


# @mcp.tool(
#     name="deep_search",
#     description="æ·±åº¦æœç´¢å·¥å…·ï¼šå…ˆé€šè¿‡Tavilyæœç´¢ï¼Œå†è‡ªåŠ¨ä½¿ç”¨Jinaçˆ¬å–å‰Nä¸ªç»“æœçš„å®Œæ•´ç½‘é¡µå†…å®¹ã€‚é€‚åˆéœ€è¦è¯¦ç»†ä¿¡æ¯çš„æŸ¥è¯¢ã€‚è¿”å›æ—¶ä¼šåœ¨åº•éƒ¨æä¾›ä¿¡æ¯æ¥æºé“¾æ¥ã€‚",
#     parameters=[
#         Parameter("query", "string", "éœ€è¦æœç´¢çš„å…³é”®è¯æˆ–è‡ªç„¶è¯­è¨€æŸ¥è¯¢è¯­å¥"),
#         Parameter("max_results", "integer", "æœç´¢å¹¶çˆ¬å–çš„ç»“æœæ•°é‡ï¼Œé»˜è®¤2ä¸ª", required=False),
#         Parameter("content_per_page", "integer", "æ¯ä¸ªç½‘é¡µè¿”å›çš„æœ€å¤§å­—ç¬¦æ•°ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®å€¼", required=False),
#     ]
# )
async def deep_search(
        query: str,
        max_results: int = 2,
        content_per_page: Optional[int] = None
):
    """
    ç»„åˆå·¥å…·ï¼šTavily æœç´¢ + Jina æ‰¹é‡çˆ¬å–
    """
    if content_per_page is None:
        content_per_page = settings.content_per_page

    # ç¬¬ä¸€æ­¥ï¼šTavily æœç´¢
    search_result = await tavily_search_internal(query, max_results)

    results = search_result.get("results", [])
    answer = search_result.get("answer", "")

    # ç¬¬äºŒæ­¥ï¼šJina çˆ¬å–ç½‘é¡µå†…å®¹
    enriched_results = []
    for result in results[:max_results]:
        url = result.get("url")
        if not url:
            continue

        # è·³è¿‡æœ¬åœ°/å†…ç½‘åœ°å€
        if any(pattern in url.lower() for pattern in ['localhost', '127.0.0.1', '192.168.', '10.', '172.16.']):
            continue

        content = await jina_crawler_internal(url, content_per_page)

        item = {
            "title": clean_text(result.get("title", ""), 100),
            "url": url,
            "snippet": clean_text(result.get("content", ""), 200),
            "score": round(result.get("score", 0), 2)
        }

        # åˆ¤æ–­æ˜¯å¦æˆåŠŸçˆ¬å–
        if content.startswith("è·å–") and "å¤±è´¥" in content:
            item["full_content"] = None
            item["fetch_error"] = content
        else:
            item["full_content"] = content
            item["content_length"] = len(content)

        enriched_results.append(item)

    # æ ¼å¼åŒ–æ¥æºé“¾æ¥
    sources_text = format_sources(results)

    return {
        "query": query,
        "answer": clean_text(answer, 500),
        "results": enriched_results,
        "sources_markdown": sources_text,
        "result_count": len(enriched_results)
    }


# ===================== æµå¼å·¥å…·å®šä¹‰ =====================

# @mcp.tool(
#     name="tavily_search_stream",
#     description="æµå¼Tavilyæœç´¢ï¼Œå®æ—¶è¿”å›æœç´¢è¿›åº¦å’Œç»“æœã€‚",
#     parameters=[
#         Parameter("query", "string", "éœ€è¦æœç´¢çš„å…³é”®è¯æˆ–è‡ªç„¶è¯­è¨€æŸ¥è¯¢è¯­å¥"),
#         Parameter("max_results", "integer", "æœ€å¤§æœç´¢ç»“æœæ•°", required=False),
#     ]
# )
async def tavily_search_stream(
        query: str,
        max_results: Optional[int] = None
) -> AsyncGenerator[dict, None]:
    """æµå¼æœç´¢ï¼šé€æ­¥è¿”å›æœç´¢çŠ¶æ€å’Œç»“æœ"""

    yield {
        "type": "status",
        "message": f"æ­£åœ¨æœç´¢: {query}",
        "progress": 0
    }

    await asyncio.sleep(0.1)

    try:
        search_result = await tavily_search_internal(query, max_results)
        results = search_result.get("results", [])
        answer = search_result.get("answer", "")

        yield {
            "type": "status",
            "message": f"æ‰¾åˆ° {len(results)} ä¸ªç»“æœ",
            "progress": 50
        }

        await asyncio.sleep(0.1)

        sources_text = format_sources(results)

        yield {
            "type": "result",
            "data": {
                "query": query,
                "answer": clean_text(answer, 500),
                "sources": [
                    {
                        "title": clean_text(r.get("title", ""), 100),
                        "url": r.get("url", ""),
                        "snippet": clean_text(r.get("content", ""), 200),
                        "score": round(r.get("score", 0), 2)
                    }
                    for r in results
                ],
                "sources_markdown": sources_text,
                "result_count": len(results)
            },
            "progress": 100
        }

    except Exception as e:
        yield {
            "type": "error",
            "message": f"æœç´¢å¤±è´¥: {str(e)}",
            "progress": 100
        }


# @mcp.tool(
#     name="deep_search_stream",
#     description="æµå¼æ·±åº¦æœç´¢ï¼Œå®æ—¶è¿”å›æœç´¢å’Œçˆ¬å–è¿›åº¦ã€‚å…ˆæœç´¢ï¼Œå†é€ä¸ªçˆ¬å–ç½‘é¡µå†…å®¹ã€‚",
#     parameters=[
#         Parameter("query", "string", "éœ€è¦æœç´¢çš„å…³é”®è¯æˆ–è‡ªç„¶è¯­è¨€æŸ¥è¯¢è¯­å¥"),
#         Parameter("max_results", "integer", "æœç´¢å¹¶çˆ¬å–çš„ç»“æœæ•°é‡ï¼Œé»˜è®¤2ä¸ª", required=False),
#         Parameter("content_per_page", "integer", "æ¯ä¸ªç½‘é¡µè¿”å›çš„æœ€å¤§å­—ç¬¦æ•°", required=False),
#     ]
# )
async def deep_search_stream(
        query: str,
        max_results: int = 2,
        content_per_page: Optional[int] = None
) -> AsyncGenerator[dict, None]:
    """æµå¼æ·±åº¦æœç´¢ï¼šTavily + Jina æµå¼è¿”å›"""

    if content_per_page is None:
        content_per_page = settings.content_per_page

    yield {
        "type": "status",
        "message": f"æ­£åœ¨æœç´¢: {query}",
        "stage": "searching",
        "progress": 0
    }

    await asyncio.sleep(0.1)

    try:
        # æœç´¢
        search_result = await tavily_search_internal(query, max_results)
        results = search_result.get("results", [])
        answer = search_result.get("answer", "")

        yield {
            "type": "status",
            "message": f"æ‰¾åˆ° {len(results)} ä¸ªç»“æœï¼Œå¼€å§‹çˆ¬å–ç½‘é¡µå†…å®¹...",
            "stage": "search_complete",
            "progress": 30
        }

        await asyncio.sleep(0.1)

        # é€ä¸ªçˆ¬å–
        enriched_results = []
        valid_results = [r for r in results[:max_results] if r.get("url")]

        for i, result in enumerate(valid_results):
            url = result.get("url")

            # è·³è¿‡æœ¬åœ°åœ°å€
            if any(pattern in url.lower() for pattern in ['localhost', '127.0.0.1', '192.168.']):
                continue

            yield {
                "type": "status",
                "message": f"æ­£åœ¨çˆ¬å–ç¬¬ {i + 1}/{len(valid_results)} ä¸ªç½‘é¡µ: {result.get('title', '')[:30]}...",
                "stage": "fetching",
                "progress": 30 + (i + 1) * (60 // len(valid_results))
            }

            content = await jina_crawler_internal(url, content_per_page)

            item = {
                "title": clean_text(result.get("title", ""), 100),
                "url": url,
                "snippet": clean_text(result.get("content", ""), 200),
                "score": round(result.get("score", 0), 2)
            }

            if content.startswith("è·å–") and "å¤±è´¥" in content:
                item["full_content"] = None
                item["fetch_error"] = content
            else:
                item["full_content"] = content
                item["content_length"] = len(content)

            enriched_results.append(item)

            yield {
                "type": "partial_result",
                "message": f"å·²å®Œæˆç¬¬ {i + 1} ä¸ªç½‘é¡µ",
                "data": item,
                "progress": 30 + (i + 1) * (60 // len(valid_results))
            }

            await asyncio.sleep(0.1)

        # æœ€ç»ˆç»“æœ
        sources_text = format_sources(results)

        yield {
            "type": "result",
            "data": {
                "query": query,
                "answer": clean_text(answer, 500),
                "results": enriched_results,
                "sources_markdown": sources_text,
                "result_count": len(enriched_results)
            },
            "progress": 100
        }

    except Exception as e:
        yield {
            "type": "error",
            "message": f"æ·±åº¦æœç´¢å¤±è´¥: {str(e)}",
            "progress": 100
        }


# ===================== FastAPI åº”ç”¨ =====================
app = FastAPI(title=mcp.name, version="1.0.0")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"]
)


@app.post("/mcp")
async def streamable_http_mcp(req: Request):
    payload = await req.json()
    method = payload.get("method")
    params = payload.get("params", {})

    try:
        if method == "initialize":
            result = mcp.initialize(
                client_info=params.get("clientInfo", {}),
                capabilities=params.get("capabilities", {})
            )
            return result

        elif method == "tools/call":
            tool_name = params["name"]
            arguments = params.get("arguments", {})
            func = mcp.tools.get(tool_name)
            if func is None:
                raise ValueError(f"Tool '{tool_name}' not found")

            async def stream_tool():
                if inspect.isasyncgenfunction(func):
                    async for chunk in func(**arguments):
                        yield json.dumps(chunk, ensure_ascii=False) + "\n"
                elif inspect.iscoroutinefunction(func):
                    result = await func(**arguments)
                    yield json.dumps({"type": "result", "data": result}, ensure_ascii=False) + "\n"
                else:
                    result = func(**arguments)
                    yield json.dumps({"type": "result", "data": result}, ensure_ascii=False) + "\n"

            return StreamingResponse(stream_tool(), media_type="application/json")

        elif method in ("tools/list", "tools/roots"):
            return mcp.tools_list()

        else:
            raise ValueError(f"Method '{method}' not found")

    except Exception as e:
        return {"error": str(e), "error_type": type(e).__name__}


@app.get("/health")
async def health():
    return {
        "status": "healthy",
        "tools_registered": len(mcp.tools),
        "tools": list(mcp.tools.keys())
    }


@app.get("/settings")
async def get_settings():
    """è·å–å½“å‰é…ç½®"""
    return {
        "tavily_max_results": settings.tavily_max_results,
        "jina_max_length": settings.jina_max_length,
        "content_per_page": settings.content_per_page,
        "jina_api_key_configured": bool(settings.jina_api_key)
    }


# ===================== å¯åŠ¨æœåŠ¡å™¨ =====================
if __name__ == "__main__":
    import uvicorn

    print(f"ğŸš€ {mcp.name} å¯åŠ¨ä¸­...")
    print(f"ğŸ“‹ å·²æ³¨å†Œ {len(mcp.tools)} ä¸ªå·¥å…·:")
    for tool_name in mcp.tools.keys():
        print(f"   - {tool_name}")
    print(f"âš™ï¸  é…ç½®: Tavilyæœ€å¤§ç»“æœ={settings.tavily_max_results}, Jinaæœ€å¤§é•¿åº¦={settings.jina_max_length}")
    uvicorn.run(app, host="0.0.0.0", port=8000)
